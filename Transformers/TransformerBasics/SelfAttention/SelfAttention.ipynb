{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Attention\n",
    "`Self Attention` is term used in Transformer based Architectures like `BERT`, `RoBERTa`, `Swin Transformer`, `ViT` and many more....!!\n",
    "\n",
    "These Architecutures trust entirely on `Self Attention` mechanisms to draw global dependencies between `inputs` and `outputs`. \n",
    "The `self-attention` mechanism allows the inputs to interact with each other (“self”) and find out who they should pay more attention to (“attention”). The outputs are aggregates of these interactions and attention scores.\n",
    "\n",
    "To Illustrate this Concept, we follow some steps\n",
    "### 1. Prepare Inputs\n",
    "We start with 3 inputs with dimension 4.\n",
    "### 2. Initialize Weights\n",
    "Every input must have 3 representations. These are `key`, `query` and `value`. In this, lets take these representations of dimension 3. So now the Weights must have a shape `[4, 3]`\n",
    "\n",
    "To obtain these, every input is multiplied with a set of weights for `keys`, a set of weights for `query` and a set of weights of `value`. Lets take the weights to be\n",
    "\n",
    "Weights for key:\n",
    "```\n",
    "[[0, 0, 1],\n",
    " [1, 1, 0],\n",
    " [0, 1, 0],\n",
    " [1, 1, 0]]\n",
    "```\n",
    "\n",
    "Weights for query:\n",
    "```\n",
    "[[1, 0, 1],\n",
    " [1, 0, 0],\n",
    " [0, 0, 1],\n",
    " [0, 1, 1]]\n",
    "```\n",
    "\n",
    "Weights for value\n",
    "```\n",
    "[[0, 2, 0],\n",
    " [0, 3, 0],\n",
    " [1, 0, 3],\n",
    " [1, 1, 0]]\n",
    "```\n",
    "These weights are initialised using a random distribution like `Gaussian`, `Xavier`, `Kaiming` distributions. \n",
    "\n",
    "### 3. Derive key, queue and value\n",
    "`Key` representation for Input 1:\n",
    "```\n",
    "               [0, 0, 1]\n",
    "[1, 0, 1, 0] x [1, 1, 0] = [0, 1, 1]\n",
    "               [0, 1, 0]\n",
    "               [1, 1, 0]\n",
    "```\n",
    "\n",
    "Use the same set of weights to get the `key` representation for Input 2:\n",
    "```\n",
    "               [0, 0, 1]\n",
    "[0, 2, 0, 2] x [1, 1, 0] = [4, 4, 0]\n",
    "               [0, 1, 0]\n",
    "               [1, 1, 0]\n",
    "```\n",
    "\n",
    "Same for Input 3:\n",
    "```\n",
    "               [0, 0, 1]\n",
    "[1, 1, 1, 1] x [1, 1, 0] = [2, 3, 1]\n",
    "               [0, 1, 0]\n",
    "               [1, 1, 0]\n",
    "```\n",
    "\n",
    "A Faster way is to `vectorize` the above operations\n",
    "```\n",
    "               [0, 0, 1]\n",
    "[1, 0, 1, 0]   [1, 1, 0]   [0, 1, 1]\n",
    "[0, 2, 0, 2] x [0, 1, 0] = [4, 4, 0]\n",
    "[1, 1, 1, 1]   [1, 1, 0]   [2, 3, 1]\n",
    "```\n",
    "\n",
    "So Now, Lets do the same to obtain `value` representations for every input:\n",
    "```\n",
    "               [0, 2, 0]\n",
    "[1, 0, 1, 0]   [0, 3, 0]   [1, 2, 3] \n",
    "[0, 2, 0, 2] x [1, 0, 3] = [2, 8, 0]\n",
    "[1, 1, 1, 1]   [1, 1, 0]   [2, 6, 3]\n",
    "```\n",
    "\n",
    "and `query` representations\n",
    "```\n",
    "               [1, 0, 1]\n",
    "[1, 0, 1, 0]   [1, 0, 0]   [1, 0, 2]\n",
    "[0, 2, 0, 2] x [0, 0, 1] = [2, 2, 2]\n",
    "[1, 1, 1, 1]   [0, 1, 1]   [2, 1, 3]\n",
    "```\n",
    "\n",
    "### 4. Calculate Attention Scores for Input 1\n",
    "\n",
    "To obtain `attention` scores, we take the dot product (`@`) between Input 1's `query` with all the `keys`. Since there are 3 `key` representations we get 3 Attention Scores.\n",
    "```\n",
    "            [0, 4, 2]\n",
    "[1, 0, 2] x [1, 4, 3] = [2, 4, 4]\n",
    "            [1, 0, 1]\n",
    "```\n",
    "`Dot` Product (@) is one of the `score functions`. There are other functions like `scaled dot product` and `additive/concat`.\n",
    "\n",
    "### 5. Calculate Softmax\n",
    "Take the `softmax` across these Attention Scores.\n",
    "```python\n",
    "softmax([2, 4, 4]) = [0.0, 0.5, 0.5]\n",
    "```\n",
    "### 6. Multiply Scores with values\n",
    "The softmaxed attention scores for each input is multiplied by its corresponding `value`. This results in 3 `alignment vectors` also known as <b>`weighted values`</b>\n",
    "\n",
    "Now, take all the `weighted values` and sum them elementwise.\n",
    "```\n",
    "  [0.0, 0.0, 0.0]\n",
    "+ [1.0, 4.0, 0.0]\n",
    "+ [1.0, 3.0, 1.5]\n",
    "-----------------\n",
    "= [2.0, 7.0, 1.5]\n",
    "```\n",
    "\n",
    "The resulting vector is `Output 1`, which is based on the `query` representation from Input 1 interacting with all other keys.\n",
    "\n",
    "### 8. Repeat for Input 2 and Input 3\n",
    "\n",
    "NOTE: The dimension of `query` and `key` must always be the same because of the `dot` product score function. However, the dimension of value may be different from `query` and `key`. The resulting output will consequently follow the dimension of `value`.\n",
    "\n",
    "\n",
    "### Code It...!!!\n",
    "Step 1: Prepare Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = [\n",
    "    [1, 0, 1, 0], # Input 1\n",
    "    [0, 2, 0, 2], # Input 2\n",
    "    [1, 1, 1, 1] # Input 3\n",
    "]\n",
    "\n",
    "x = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Initialize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_key = [\n",
    "  [0, 0, 1],\n",
    "  [1, 1, 0],\n",
    "  [0, 1, 0],\n",
    "  [1, 1, 0]\n",
    "]\n",
    "w_query = [\n",
    "  [1, 0, 1],\n",
    "  [1, 0, 0],\n",
    "  [0, 0, 1],\n",
    "  [0, 1, 1]\n",
    "]\n",
    "w_value = [\n",
    "  [0, 2, 0],\n",
    "  [0, 3, 0],\n",
    "  [1, 0, 3],\n",
    "  [1, 1, 0]\n",
    "]\n",
    "\n",
    "w_key = torch.tensor(w_key, dtype=torch.float32)\n",
    "w_query = torch.tensor(w_query, dtype=torch.float32)\n",
    "w_value = torch.tensor(w_value, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Derive key, query and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1.],\n",
      "        [4., 4., 0.],\n",
      "        [2., 3., 1.]])\n"
     ]
    }
   ],
   "source": [
    "keys = x @ w_key\n",
    "querys = x @ w_query\n",
    "values = x @ w_value\n",
    "\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 2.],\n",
      "        [2., 2., 2.],\n",
      "        [2., 1., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(querys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 8., 0.],\n",
      "        [2., 6., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Calculate Attention Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.,  4.],\n",
      "        [ 4., 16., 12.],\n",
      "        [ 4., 12., 10.]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = querys @ keys.T\n",
    "\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Calculate Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6.3379e-02, 4.6831e-01, 4.6831e-01],\n",
      "        [6.0337e-06, 9.8201e-01, 1.7986e-02],\n",
      "        [2.9539e-04, 8.8054e-01, 1.1917e-01]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_softmax = torch.nn.functional.softmax(attn_scores, dim=-1)\n",
    "\n",
    "print(attn_scores_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize / Approximate the Attention Scores\n",
    "attn_scores_softmax = [\n",
    "  [0.0, 0.5, 0.5],\n",
    "  [0.0, 1.0, 0.0],\n",
    "  [0.0, 0.9, 0.1]\n",
    "]\n",
    "attn_scores_softmax = torch.tensor(attn_scores_softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.5000, 0.5000],\n",
       "        [0.0000, 1.0000, 0.0000],\n",
       "        [0.0000, 0.9000, 0.1000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_scores_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Multiply Attention Scores with Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 4.0000, 0.0000],\n",
      "         [2.0000, 8.0000, 0.0000],\n",
      "         [1.8000, 7.2000, 0.0000]],\n",
      "\n",
      "        [[1.0000, 3.0000, 1.5000],\n",
      "         [0.0000, 0.0000, 0.0000],\n",
      "         [0.2000, 0.6000, 0.3000]]])\n"
     ]
    }
   ],
   "source": [
    "weighted_values = values[:, None] * attn_scores_softmax.T[:, :, None]\n",
    "\n",
    "print(weighted_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Sum Weighted Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 7.0000, 1.5000],\n",
      "        [2.0000, 8.0000, 0.0000],\n",
      "        [2.0000, 7.8000, 0.3000]])\n"
     ]
    }
   ],
   "source": [
    "outputs = weighted_values.sum(dim=0)\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02e8b29f27383623620a81b44ff2109e24f067f3b1a958c640937ff95ee3ec72"
  },
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
