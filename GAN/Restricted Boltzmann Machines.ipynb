{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Boltzmann Machines using ScratchKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.openml module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "from scratchkit.utils.misc import bar_widgets\n",
    "from scratchkit.utils import batch_iterator\n",
    "from scratchkit.dl.activations import Sigmoid\n",
    "\n",
    "from sklearn.datasets.openml import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = Sigmoid()\n",
    "\n",
    "class RBM():\n",
    "    \"\"\"\n",
    "    Bernoulli Restricted Boltzmann Machine (RBM)\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_hidden: int:\n",
    "        The number of processing nodes (neurons) in the hidden layer. \n",
    "    learning_rate: float\n",
    "        The step length that will be used when updating the weights.\n",
    "    batch_size: int\n",
    "        The size of the mini-batch used to calculate each weight update.\n",
    "    n_iterations: float\n",
    "        The number of training iterations the algorithm will tune the weights for.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, n_hidden=128, learning_rate=0.1, batch_size=10, n_iterations=100):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = learning_rate\n",
    "        self.n_hidden = n_hidden\n",
    "        self.progressbar = progressbar.ProgressBar(widgets=bar_widgets)\n",
    "\n",
    "    def _initialize_weights(self, X):\n",
    "        n_visible = X.shape[1]\n",
    "        self.W = np.random.normal(scale=0.1, size=(n_visible, self.n_hidden))\n",
    "        self.v0 = np.zeros(n_visible) # Bias visible\n",
    "        self.h0 = np.zeros(self.n_hidden) # Bias hidden\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self._initialize_weights(X)\n",
    "\n",
    "        self.training_errors = []\n",
    "        self.training_reconstructions = []\n",
    "        for _ in self.progressbar(range(self.n_iterations)):\n",
    "            batch_errors = []\n",
    "            for batch in batch_iterator(X, batch_size=self.batch_size):\n",
    "                # Positive phase\n",
    "                positive_hidden = sigmoid(batch.dot(self.W) + self.h0)\n",
    "                hidden_states = self._sample(positive_hidden)\n",
    "                positive_associations = batch.T.dot(positive_hidden)\n",
    "\n",
    "                # Negative phase\n",
    "                negative_visible = sigmoid(hidden_states.dot(self.W.T) + self.v0)\n",
    "                negative_visible = self._sample(negative_visible)\n",
    "                negative_hidden = sigmoid(negative_visible.dot(self.W) + self.h0)\n",
    "                negative_associations = negative_visible.T.dot(negative_hidden)\n",
    "\n",
    "                self.W  += self.lr * (positive_associations - negative_associations)\n",
    "                self.h0 += self.lr * (positive_hidden.sum(axis=0) - negative_hidden.sum(axis=0))\n",
    "                self.v0 += self.lr * (batch.sum(axis=0) - negative_visible.sum(axis=0))\n",
    "\n",
    "                batch_errors.append(np.mean((batch - negative_visible) ** 2))\n",
    "\n",
    "            self.training_errors.append(np.mean(batch_errors))\n",
    "            # Reconstruct a batch of images from the training set\n",
    "            idx = np.random.choice(range(X.shape[0]), self.batch_size)\n",
    "            self.training_reconstructions.append(self.reconstruct(X[idx]))\n",
    "\n",
    "    def _sample(self, X):\n",
    "        return X > np.random.random_sample(size=X.shape)\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        positive_hidden = sigmoid(X.dot(self.W) + self.h0)\n",
    "        hidden_states = self._sample(positive_hidden)\n",
    "        negative_visible = sigmoid(hidden_states.dot(self.W.T) + self.v0)\n",
    "        return negative_visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100% [-----------------------------------------------] Time:  0:48:06\n"
     ]
    }
   ],
   "source": [
    "# Run it\n",
    "mnist = fetch_openml('mnist_784')\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# Rescale [-1, 1]\n",
    "X = (X.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "model = RBM()\n",
    "model.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.RBM at 0x1f177648610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
